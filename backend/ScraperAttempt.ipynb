{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc588542-2a20-47b0-9201-2c733a7a72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "state_dict = {\"ca\":\"California\",\"sc\":\"South Carolina\"} #Set up dictionary that matches state initials to state name\n",
    "sport_set = {\"basketball\",\"baseball\",\"football\"} #Set up sports set \n",
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"}\n",
    "relevant_words = {}\n",
    "with open(\"Resources/SiteInfo.json\", \"r\") as f:\n",
    "    json_dev_file = json.load(f)\n",
    "\n",
    "def get_html(URL): #gets html in text\n",
    "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "    page = requests.get(URL,headers=header) \n",
    "    soup = BeautifulSoup(page.text,'html.parser') #take html\n",
    "    return soup\n",
    "\n",
    "##going with simplicity here, \n",
    "def grab_hrefs(page_elem):\n",
    "    tags = []\n",
    "    tags = page_elem.find_all('a')\n",
    "    links = [tag['href'] for tag in tags if 'href' in tag.attrs] #find links\n",
    "    return links\n",
    "\n",
    "def grab_id_parent(page_elem,pg_id):\n",
    "    return page_elem.find(id=pg_id)\n",
    "def grab_scripts(page_elem,regex = re.compile('')):\n",
    "    #return [script for script in page_elem.find_all(\"script\") if regex.search(script.attrs['src'])]\n",
    "    return page_elem.find_all(\"script\")\n",
    "    \n",
    "#IN USE NOW \n",
    "def grab_team_hrefs(page_elem):\n",
    "    links = grab_hrefs(page_elem)\n",
    "\n",
    "    ####REWORK vvvvv to work with other states via an container\n",
    "    team_links = [link for link in links if link.startswith(\"/ca/\") and link.endswith(\"/basketball/\") and link != \"/ca/basketball/\"]\n",
    "    ####HARDCODED RN but can use relevant words from parse_url_context in the future to decipher relevant links\n",
    "    return team_links\n",
    "\n",
    "def grab_player_hrefs(page_elem): #eventually should make respective classes that override this function\n",
    "    links = grab_hrefs(page_elem)\n",
    "    relevant_pattern = r'careerid=[a-z0-9]+' #eventually, it should read off json to get a regex depending on site\n",
    "    player_links = [link for link in links if re.search(relevant_pattern,link)]\n",
    "    return player_links\n",
    "#WIP\n",
    "\n",
    "def grab_player_info(page_elem):\n",
    "    ##there is a big script.\n",
    "    player_scripts = grab_id_parent(ex_player_pg, '__NEXT_DATA__')\n",
    "    return\n",
    "#WIP might not need\n",
    "def get_team_URL(page_html):\n",
    "    #try to guess which link is the teams URL on a given site\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba971b96-c039-4056-b317-07389589323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laf_ball_roster_html = get_html(\"https://www.maxpreps.com/ca/lafayette/acalanes-dons/basketball/roster/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2333588c-6627-4a56-9e06-ec11bd99a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_page_html = get_html(\"https://www.maxpreps.com/ca/basketball/schools/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45dd0bfb-fd42-4bc1-a4e3-bd1e9607e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IF WANT TO TEST TEAMS, THERE ARE 200 TEAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ee6009-f6e2-42cc-8828-d8a8f921a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "team_links = grab_team_hrefs(team_page_html)\n",
    "print(len(team_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b1b1e30-4f57-46e5-8b52-52a51a490d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 players\n",
      "['/ca/lafayette/acalanes-dons/athletes/preston-hilsabeck/?careerid=hpb7k1kir1dm6', '/ca/lafayette/acalanes-dons/athletes/cameron-hood/?careerid=dsg8ao87v6ep9', '/ca/lafayette/acalanes-dons/athletes/julian-hood/?careerid=56mf96hmdg7o8', '/ca/lafayette/acalanes-dons/athletes/justice-hembrador/?careerid=2kfkn0i2o19bb', '/ca/lafayette/acalanes-dons/athletes/sam-phillips/?careerid=qd4gfkvejm577', '/ca/lafayette/acalanes-dons/athletes/bryce-mansour/?careerid=hblf6vc03u0bb', '/ca/lafayette/acalanes-dons/athletes/aj-hastings/?careerid=5s34l10a9ftee', '/ca/lafayette/acalanes-dons/athletes/evan-palmer/?careerid=e40dlmenhoaaa', '/ca/lafayette/acalanes-dons/athletes/shea-stahl/?careerid=d8rohq05aqrvf', '/ca/lafayette/acalanes-dons/athletes/jon-macleod/?careerid=23f38c690m8td', '/ca/lafayette/acalanes-dons/athletes/gavin-dodge/?careerid=2eorqhnhgcb44', '/ca/lafayette/acalanes-dons/athletes/aakash-agarwal/?careerid=9u5jbbjt91tm6', '/ca/lafayette/acalanes-dons/athletes/landon-deily/?careerid=6jneeijvodtue']\n"
     ]
    }
   ],
   "source": [
    "#FOR SOME REASON THEY HAVE A SPACE which throws off search.\n",
    "#develop context based title finding \n",
    "member_links = grab_roster_hrefs(laf_ball_roster_html)\n",
    "print(f'{len(member_links)} players\\n{member_links}') #as of rn, there are 13 players on this team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e55fda0f-dbf3-4f56-ad03-fb32dcb6ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "####PLAYER LOGIC FROM ROSTER#####\n",
    "\n",
    "#given a team, find the roster link <-- skip since we hardcode it rn\n",
    "\n",
    "#TODO: from rosters page, find player links\n",
    "#it is also just maxpreps.com{whatever player we found from roster} ... same goes for any links we find; it is just maxpreps.com{found links}\n",
    "site_url = json_dev_file['maxpreps']['site_url']\n",
    "ex_player_pg = get_html(f\"{site_url}{member_links[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9fd24192-b70b-4a55-b662-f08bcb1bdb0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##CAN USE FIRESTORE ATTRIBUTES FOR BASKETBALL TO LOOK FOR HEADERS THAT HAVE THAT INFO\n",
    "player_json_script = grab_id_parent(ex_player_pg, '__NEXT_DATA__')\n",
    "json_data = json.loads(player_json_script.string)\n",
    "with open('ex_player_info.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5647744d-950e-4869-bab8-587e86b6a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO tentative\n",
    "    #continue on roster directory logic -- DONE\n",
    "    #continue on player page logic -- DONE \n",
    "    #make it create json file that maps teams(from DB) to links\n",
    "        #\"data_pipeline_shortcuts\":{\n",
    "        #\"team_url_pattern\": \"\",\n",
    "        #\"team_page_url_pattern\": \"\",\n",
    "        #\"roster_page_url_pattern\": \"\",\n",
    "        #\"player_page_url_pattern\": \"\"\n",
    "        #},\n",
    "    #make known path for specific website and add to relevant words\n",
    "    #eventually make datastructures for these things: teams and players so we can serialize and deserialize from db for QoL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e70888-0e88-4aa8-94a6-0bb3727e3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EVERYTHING BELOW IS JUST WIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da71d5e2-bccb-4119-b732-a10b98a4dbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'basketball', 'schools']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"} #could also be relevant words when looking for links that match page context \n",
    "URL = \"https://www.maxpreps.com/ca/basketball/schools/\"\n",
    "url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "url_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f43b7b-d7c7-473f-9dc5-384ead62e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = soup.find_all(['h1','h2','h3'])\n",
    "target_text[-1].get_text()\n",
    "target_text #WIP on pinpointing exact div-- for the far future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafda1fd-62aa-4081-9abb-829a16a10a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url_context(URL, redundant_words): # remove maxpreps and https:// etc but keep keywords like ca\n",
    "    # sc, Basketball, Boys to use and find relevant themes. This way, we can remove redundant words from links within page that may point to itself\n",
    "    #can use these words and additional context to generate likelihood of teams div\n",
    "    #not use right now\n",
    "    #chop up url\n",
    "    url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "    return url_words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
