{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cc588542-2a20-47b0-9201-2c733a7a72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "state_dict = {\"ca\":\"California\",\"sc\":\"South Carolina\"} #Set up dictionary that matches state initials to state name\n",
    "sport_set = {\"basketball\",\"baseball\",\"football\"} #Set up sports set \n",
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"}\n",
    "DEV = 1\n",
    "\n",
    "relevant_words = {}\n",
    "\n",
    "####FUNCTIONAL FOR TEAMS IF SPECIFIC URL PROVIDED####\n",
    "#IN USE NOW\n",
    "def find_node(html,specific_string = \"\"):\n",
    "    if specific_string == \"\":\n",
    "        print(\"NOT YET READY\")\n",
    "        return 0\n",
    "        #wip\n",
    "        #TODO\n",
    "        \n",
    "    target_text = html.find(string=specific_string)\n",
    "    print(target_text)\n",
    "    #returns navigable string so we gotta go to parent node\n",
    "    #can set up here with predetermined syntax via json lookup or guess. go with json for now.\n",
    "    #set up error handling\n",
    "    return target_text.find_parent()\n",
    "\n",
    "def grab_links(page_elem):\n",
    "    tags = []\n",
    "    curr_elem = page_elem\n",
    "    while len(tags)==0 and curr_elem.name not in {\"body\", \"html\", \"[document]\"}: \n",
    "        search_set = [curr_elem] + curr_elem.find_next_siblings()\n",
    "        for item in search_set:\n",
    "            found_links = item.find_all('a') #find all anchor tags \n",
    "            if found_links:\n",
    "                tags.extend(found_links) \n",
    "        curr_elem = curr_elem.parent\n",
    "    links = [tag['href'] for tag in tags if 'href' in tag.attrs] #find links\n",
    "    return links\n",
    "\n",
    "    \n",
    "#IN USE NOW \n",
    "def grab_team_links(teams_node):\n",
    "    links = grab_links(teams_node)\n",
    "\n",
    "    ####REWORK vvvvv\n",
    "    team_links = [link for link in links if link.startswith(\"/ca/\") and link.endswith(\"/basketball/\") and link != \"/ca/basketball/\"]\n",
    "    ####HARDCODED RN but can use relevant words from parse_url_context in the future to decipher relevant links\n",
    "    return team_links\n",
    "\n",
    "def grab_roster_links(roster_element): #eventually should make respective classes that override this function\n",
    "    links = grab_links(roster_element)\n",
    "    relevant_pattern = r'careerid=[a-z0-9]+' #eventually, it should read off json to get a regex depending on site\n",
    "    player_links = [link for link in links if re.search(relevant_pattern,link)]\n",
    "    return player_links\n",
    "\n",
    "def get_html(URL): #gets html in text\n",
    "    page = requests.get(URL) \n",
    "    soup = BeautifulSoup(page.text,'html.parser') #take html\n",
    "    return soup\n",
    "\n",
    "#WIP\n",
    "def parse_url_context(URL, redundant_words): # remove maxpreps and https:// etc but keep keywords like ca\n",
    "    # sc, Basketball, Boys to use and find relevant themes. This way, we can remove redundant words from links within page that may point to itself\n",
    "    #can use these words and additional context to generate likelihood of teams div\n",
    "    #not use right now\n",
    "    #chop up url\n",
    "    url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "    return url_words\n",
    "\n",
    "#WIP might not need\n",
    "def get_team_URL(page_html):\n",
    "    #try to guess which link is the teams URL on a given site\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba971b96-c039-4056-b317-07389589323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laf_ball_roster_html = get_html(\"https://www.maxpreps.com/ca/lafayette/acalanes-dons/basketball/roster/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2333588c-6627-4a56-9e06-ec11bd99a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_page_html = get_html(\"https://www.maxpreps.com/ca/basketball/schools/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd0bfb-fd42-4bc1-a4e3-bd1e9607e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IF WANT TO TEST TEAMS, THERE ARE 200 TEAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6b1b1e30-4f57-46e5-8b52-52a51a490d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acalanes  Basketball Roster\n",
      "13 players\n",
      "['/ca/lafayette/acalanes-dons/athletes/preston-hilsabeck/?careerid=hpb7k1kir1dm6', '/ca/lafayette/acalanes-dons/athletes/cameron-hood/?careerid=dsg8ao87v6ep9', '/ca/lafayette/acalanes-dons/athletes/julian-hood/?careerid=56mf96hmdg7o8', '/ca/lafayette/acalanes-dons/athletes/justice-hembrador/?careerid=2kfkn0i2o19bb', '/ca/lafayette/acalanes-dons/athletes/sam-phillips/?careerid=qd4gfkvejm577', '/ca/lafayette/acalanes-dons/athletes/bryce-mansour/?careerid=hblf6vc03u0bb', '/ca/lafayette/acalanes-dons/athletes/aj-hastings/?careerid=5s34l10a9ftee', '/ca/lafayette/acalanes-dons/athletes/evan-palmer/?careerid=e40dlmenhoaaa', '/ca/lafayette/acalanes-dons/athletes/shea-stahl/?careerid=d8rohq05aqrvf', '/ca/lafayette/acalanes-dons/athletes/jon-macleod/?careerid=23f38c690m8td', '/ca/lafayette/acalanes-dons/athletes/gavin-dodge/?careerid=2eorqhnhgcb44', '/ca/lafayette/acalanes-dons/athletes/aakash-agarwal/?careerid=9u5jbbjt91tm6', '/ca/lafayette/acalanes-dons/athletes/landon-deily/?careerid=6jneeijvodtue']\n"
     ]
    }
   ],
   "source": [
    "roster_element = find_node(laf_ball_roster_html,\"Acalanes  Basketball Roster\") #FOR SOME REASON THEY HAVE A SPACE which throws off search.\n",
    "#develop context based title finding \n",
    "member_links = grab_roster_links(roster_element)\n",
    "print(f'{len(member_links)} players\\n{member_links}') #as of rn, there are 13 players on this team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e55fda0f-dbf3-4f56-ad03-fb32dcb6ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acalanes  Basketball Roster\n"
     ]
    }
   ],
   "source": [
    "####PLAYER LOGIC FROM ROSTER#####\n",
    "\n",
    "#given a team, find the roster link <-- skip since we hardcode it rn\n",
    "\n",
    "#TODO: from rosters page, find player links\n",
    "\n",
    "def grab_player_links(roster_element):\n",
    "    links = grab_links(roster_element)\n",
    "\n",
    "roster_elem = find_node(laf_ball_roster_html,\"Acalanes  Basketball Roster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8489b90-890f-42e4-b554-0330ed5efd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO HERE: grab teams. then, from each team, slap that url onto maxpreps and look for roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647744d-950e-4869-bab8-587e86b6a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO tentative\n",
    "    #continue on roster directory logic -- SOMEWHAT DONE\n",
    "    #continue on player page logic\n",
    "    #make it create json file that maps teams(from DB) to links\n",
    "        #\"data_pipeline_shortcuts\":{\n",
    "        #\"team_url_pattern\": \"\",\n",
    "        #\"team_page_url_pattern\": \"\",\n",
    "        #\"roster_page_url_pattern\": \"\",\n",
    "        #\"player_page_url_pattern\": \"\"\n",
    "        #},\n",
    "    #make known path for specific website and add to relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e70888-0e88-4aa8-94a6-0bb3727e3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EVERYTHING BELOW IS JUST WIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "da71d5e2-bccb-4119-b732-a10b98a4dbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'basketball', 'schools']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"} #could also be relevant words when looking for links that match page context \n",
    "URL = \"https://www.maxpreps.com/ca/basketball/schools/\"\n",
    "url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "url_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f43b7b-d7c7-473f-9dc5-384ead62e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = soup.find_all(['h1','h2','h3'])\n",
    "target_text[-1].get_text()\n",
    "target_text #WIP on pinpointing exact div-- for the far future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
