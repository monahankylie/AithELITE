{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817c4d34-70c3-48b4-b7cd-b367fe6f7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "page = requests.get(\"https://www.maxpreps.com/ca/basketball/schools/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bf3f5b-acdc-4762-afa8-6a49a583b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "soup = BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fb79ca-ccae-4c58-a844-3909b3188d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = soup.find(string=\"California Boys Basketball High School Teams\") #returns navigable string so we gotta gop to parent\n",
    "curr_elem = target_text.find_parent()\n",
    "tags = []\n",
    "while len(tags)==0 and curr_elem.name != '[document]': \n",
    "    search_set = [curr_elem] + curr_elem.find_next_siblings()\n",
    "    for item in search_set:\n",
    "        found_links = item.find_all('a') #find all anchor tags \n",
    "        if found_links:\n",
    "            tags.extend(found_links) \n",
    "    curr_elem = curr_elem.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0922072f-7499-474b-b50e-aa4772a50ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [tag['href'] for tag in tags if 'href' in tag.attrs] #each element is an object and *.attr is a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9f4745d-8457-4505-a743-065c0528671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_hsball = [link for link in links if link.startswith(\"/ca/\") and link.endswith(\"/basketball/\") and link != \"/ca/basketball/\"] #[expression for item in iterable if condition]\n",
    "#each element is an object and *.attr is a dictionary\n",
    "#also on MAXPREPS it is state/county/team/basketball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70a9108e-7460-4e2b-b5b4-c1b7957623bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(links_hsball)) #FUNCTIONAL TO HERE also, 200 teams currently in CA as of Feb 17 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefac54d-5914-4a6b-afc1-d13cbe4d61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.maxpreps.com/SC/basketball/schools/\")\n",
    "soup = BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9457b69e-cd8f-453e-bd8a-c761dcd9c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = soup.find(string=\"South Carolina Boys Basketball High School Teams\") #returns navigable string so we gotta gop to parent\n",
    "curr_elem = target_text.find_parent()\n",
    "tags = []\n",
    "while len(tags)==0 and curr_elem.name != '[document]': \n",
    "    search_set = [curr_elem] + curr_elem.find_next_siblings()\n",
    "    for item in search_set:\n",
    "        found_links = item.find_all('a') #find all anchor tags \n",
    "        if found_links:\n",
    "            tags.extend(found_links) \n",
    "    curr_elem = curr_elem.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2407ace7-b1ed-4e54-b989-3a9e14adaf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [tag['href'] for tag in tags if 'href' in tag.attrs] #each element is an object and *.attr is a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "958a2050-3ee2-4567-aa1d-14169fcf471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.maxpreps.com/ca/basketball/schools/\")\n",
    "soup = BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9f43b7b-d7c7-473f-9dc5-384ead62e2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"heading_100_bold\">POPULAR SPORTS</h3>,\n",
       " <h3 class=\"sc-9bfabda6-1 iKDzCD heading_100_bold\">Apps</h3>,\n",
       " <h3 class=\"sc-9bfabda6-1 iKDzCD heading_100_bold\">Pro Photography</h3>,\n",
       " <h3 class=\"sc-9bfabda6-1 iKDzCD heading_100_bold\">Watch</h3>,\n",
       " <h3 class=\"sc-9bfabda6-1 iKDzCD heading_100_bold\">Content Contributors</h3>,\n",
       " <h3 class=\"sc-9bfabda6-1 iKDzCD heading_100_bold\">Tickets</h3>,\n",
       " <h1 class=\"sc-e96201a1-0 iItjPn\" title=\"South Carolina Boys Basketball High School Teams\">South Carolina Boys Basketball High School Teams</h1>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text = soup.find_all(['h1','h2','h3'])\n",
    "target_text[-1].get_text()\n",
    "target_text #WIP on pinpointing exact div-- for the far future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc588542-2a20-47b0-9201-2c733a7a72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "state_dict = {\"ca\":\"California\",\"sc\":\"South Carolina\"} #Set up dictionary that matches state initials to state name\n",
    "sport_set = {\"basketball\",\"baseball\",\"football\"} #Set up sports set \n",
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"}\n",
    "DEV = 1\n",
    "\n",
    "relevant_words = {}\n",
    "\n",
    "#IN USE NOW\n",
    "def find_node(html,title = \"\"):\n",
    "    if title == \"\":\n",
    "        print(\"NOT YET READY\")\n",
    "        return 0\n",
    "        #attempt to find title but for rn we hardcode it\n",
    "        #TODO\n",
    "        \n",
    "    target_text = html.find(string=title)\n",
    "    #returns navigable string so we gotta go to parent node\n",
    "    #can set up here with predetermined syntax via json lookup or guess. go with json for now.\n",
    "    return target_text.find_parent()\n",
    "\n",
    "def grab_links(page_elem):\n",
    "    tags = []\n",
    "    curr_elem = page_elem\n",
    "    while len(tags)==0 and curr_elem.name != ['document']: \n",
    "        search_set = [curr_elem] + curr_elem.find_next_siblings()\n",
    "        for item in search_set:\n",
    "            found_links = item.find_all('a') #find all anchor tags \n",
    "            if found_links:\n",
    "                tags.extend(found_links) \n",
    "        curr_elem = curr_elem.parent\n",
    "    links = [tag['href'] for tag in tags if 'href' in tag.attrs] #find links\n",
    "    return links\n",
    "\n",
    "    \n",
    "#IN USE NOW\n",
    "def grab_team_links(teams_node):\n",
    "    links = grab_links(teams_node)\n",
    "\n",
    "    ####REWORK vvvvv\n",
    "    team_links = [link for link in links if link.startswith(\"/ca/\") and link.endswith(\"/basketball/\") and link != \"/ca/basketball/\"]\n",
    "    ####HARDCODED RN but can use relevant words from parse_url_context in the future to decipher relevant links\n",
    "    return team_links\n",
    "\n",
    "def get_html(URL): #gets html in text\n",
    "    page = requests.get(URL) \n",
    "    soup = BeautifulSoup(page.text,'html.parser') #take html\n",
    "    return soup\n",
    "\n",
    "#WIP\n",
    "def parse_url_context(URL, redundant_words): # remove maxpreps and https:// etc but keep keywords like ca\n",
    "    # sc, Basketball, Boys to use and find relevant themes. This way, we can remove redundant words from links within page that may point to itself\n",
    "    #can use these words and additional context to generate likelihood of teams div\n",
    "    #not use right now\n",
    "    #chop up url\n",
    "    url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "    return url_words\n",
    "\n",
    "#WIP\n",
    "def get_team_URL(page_html):\n",
    "    #try to guess which link is the teams URL on a given site\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2333588c-6627-4a56-9e06-ec11bd99a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(grab_team_links(team_node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "199a8ac5-7018-487e-8ead-92b20419545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://www.maxpreps.com/ca/basketball/schools/\"\n",
    "with open(\"Resources/SiteInfo.json\", \"r\") as f:\n",
    "    site_rules = json.load(f)\n",
    "maxprep_set = site_rules['maxpreps'] \n",
    "dev_set = maxprep_set['CA_DEV']\n",
    "team_node = find_teams_node(dev_set['title'])\n",
    "#print(grab_team_links(team_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da71d5e2-bccb-4119-b732-a10b98a4dbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'basketball', 'schools']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant_words = {\"maxpreps\",\"http\",\"https\",\"www\",\"com\"}\n",
    "URL = \"https://www.maxpreps.com/ca/basketball/schools/\"\n",
    "url_words = [w for w in re.split(r'[/\\.:]+',URL) if w.lower() not in redundant_words and len(w) > 0]\n",
    "url_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e55fda0f-dbf3-4f56-ad03-fb32dcb6ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "####PLAYER LOGIC FROM ROSTER#####\n",
    "\n",
    "#given a team, find the roster link <-- skip since we hardcode it rn\n",
    "\n",
    "#TODO: from rosters page, find player links\n",
    "\n",
    "def grab_player_links(roster_element):\n",
    "    links = grab_links(roster_element)\n",
    "\n",
    "roster_elem = find_node(laf_ball_roster_html,\"Acalanes  Basketball Roster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98c4388f-d9ba-4ef2-bb93-f5ba1eb4e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"title\">Acalanes  Basketball Roster</h1>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ba971b96-c039-4056-b317-07389589323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laf_ball_roster_html = get_html(\"https://www.maxpreps.com/ca/lafayette/acalanes-dons/basketball/roster/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b1b1e30-4f57-46e5-8b52-52a51a490d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ca/lafayette/acalanes-dons/basketball/roster/',\n",
       " '/ca/lafayette/acalanes-dons/basketball/staff/',\n",
       " '/ca/lafayette/acalanes-dons/athletes/preston-hilsabeck/?careerid=hpb7k1kir1dm6',\n",
       " '/ca/lafayette/acalanes-dons/athletes/cameron-hood/?careerid=dsg8ao87v6ep9',\n",
       " '/ca/lafayette/acalanes-dons/athletes/julian-hood/?careerid=56mf96hmdg7o8',\n",
       " '/ca/lafayette/acalanes-dons/athletes/justice-hembrador/?careerid=2kfkn0i2o19bb',\n",
       " '/ca/lafayette/acalanes-dons/athletes/sam-phillips/?careerid=qd4gfkvejm577',\n",
       " '/ca/lafayette/acalanes-dons/athletes/bryce-mansour/?careerid=hblf6vc03u0bb',\n",
       " '/ca/lafayette/acalanes-dons/athletes/aj-hastings/?careerid=5s34l10a9ftee',\n",
       " '/ca/lafayette/acalanes-dons/athletes/evan-palmer/?careerid=e40dlmenhoaaa',\n",
       " '/ca/lafayette/acalanes-dons/athletes/shea-stahl/?careerid=d8rohq05aqrvf',\n",
       " '/ca/lafayette/acalanes-dons/athletes/jon-macleod/?careerid=23f38c690m8td',\n",
       " '/ca/lafayette/acalanes-dons/athletes/gavin-dodge/?careerid=2eorqhnhgcb44',\n",
       " '/ca/lafayette/acalanes-dons/athletes/aakash-agarwal/?careerid=9u5jbbjt91tm6',\n",
       " '/ca/lafayette/acalanes-dons/athletes/landon-deily/?careerid=6jneeijvodtue',\n",
       " '/utility/support/correction.aspx?t=1&schoolid=e6042da9-e5ce-4f18-a841-ae5e6cf48015&ssid=ee7cf537-7394-4430-88ca-becaabda286c&state=CA',\n",
       " '/ca/lafayette/acalanes-dons/basketball/roster/all-time/']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roster_element = laf_ball_roster_html.find(string = \"Acalanes  Basketball Roster\").find_parent()\n",
    "links = grab_links(roster_element)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647744d-950e-4869-bab8-587e86b6a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "    #continue on roster directory logic\n",
    "    #continue on player page logic\n",
    "    #make it create json file that maps teams(from DB) to links\n",
    "        #\"data_pipeline_shortcuts\":{\n",
    "        #\"team_url_pattern\": \"\",\n",
    "        #\"team_page_url_pattern\": \"\",\n",
    "        #\"roster_page_url_pattern\": \"\",\n",
    "        #\"player_page_url_pattern\": \"\"\n",
    "        #},"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
